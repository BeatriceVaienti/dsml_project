{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#we read the training data\n",
    "df = pd.read_csv('../training/training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>n_words</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
       "      <td>C1</td>\n",
       "      <td>38</td>\n",
       "      <td>5.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
       "      <td>A1</td>\n",
       "      <td>12</td>\n",
       "      <td>4.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Le test de niveau en français est sur le site ...</td>\n",
       "      <td>A1</td>\n",
       "      <td>13</td>\n",
       "      <td>4.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
       "      <td>A1</td>\n",
       "      <td>8</td>\n",
       "      <td>4.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
       "      <td>B1</td>\n",
       "      <td>34</td>\n",
       "      <td>5.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>4795</td>\n",
       "      <td>C'est pourquoi, il décida de remplacer les hab...</td>\n",
       "      <td>B2</td>\n",
       "      <td>26</td>\n",
       "      <td>5.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>4796</td>\n",
       "      <td>Il avait une de ces pâleurs splendides qui don...</td>\n",
       "      <td>C1</td>\n",
       "      <td>21</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>4797</td>\n",
       "      <td>Et le premier samedi de chaque mois, venez ren...</td>\n",
       "      <td>A2</td>\n",
       "      <td>14</td>\n",
       "      <td>4.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>4798</td>\n",
       "      <td>Les coûts liés à la journalisation n'étant pas...</td>\n",
       "      <td>C2</td>\n",
       "      <td>32</td>\n",
       "      <td>6.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>4799</td>\n",
       "      <td>Sur le sable, la mer haletait de toute la resp...</td>\n",
       "      <td>C2</td>\n",
       "      <td>17</td>\n",
       "      <td>4.647059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4800 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           sentence difficulty  \\\n",
       "0        0  Les coûts kilométriques réels peuvent diverger...         C1   \n",
       "1        1  Le bleu, c'est ma couleur préférée mais je n'a...         A1   \n",
       "2        2  Le test de niveau en français est sur le site ...         A1   \n",
       "3        3           Est-ce que ton mari est aussi de Boston?         A1   \n",
       "4        4  Dans les écoles de commerce, dans les couloirs...         B1   \n",
       "...    ...                                                ...        ...   \n",
       "4795  4795  C'est pourquoi, il décida de remplacer les hab...         B2   \n",
       "4796  4796  Il avait une de ces pâleurs splendides qui don...         C1   \n",
       "4797  4797  Et le premier samedi de chaque mois, venez ren...         A2   \n",
       "4798  4798  Les coûts liés à la journalisation n'étant pas...         C2   \n",
       "4799  4799  Sur le sable, la mer haletait de toute la resp...         C2   \n",
       "\n",
       "      n_words  avg_word_length  \n",
       "0          38         5.736842  \n",
       "1          12         4.250000  \n",
       "2          13         4.153846  \n",
       "3           8         4.125000  \n",
       "4          34         5.176471  \n",
       "...       ...              ...  \n",
       "4795       26         5.384615  \n",
       "4796       21         4.666667  \n",
       "4797       14         4.785714  \n",
       "4798       32         6.093750  \n",
       "4799       17         4.647059  \n",
       "\n",
       "[4800 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with missing 'sentence' or 'difficulty' in training data\n",
    "df = df.dropna(subset=['sentence', 'difficulty'])\n",
    "# remove duplicates\n",
    "df = df.drop_duplicates(subset=['sentence'])\n",
    "#add a column with the number of words in the text ('sentence' column)\n",
    "df['n_words'] = df['sentence'].apply(lambda x: len(x.split()))\n",
    "#add a column with the average length of the words in the text ('sentence' column)\n",
    "df['avg_word_length'] = df['sentence'].apply(lambda x: np.mean([len(w) for w in x.split()]))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difficulty\n",
      "A1    813\n",
      "A2    795\n",
      "B1    795\n",
      "B2    792\n",
      "C1    798\n",
      "C2    807\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# we first want to understand the features of our dataset, so we will see how many sentences are available per level of difficulty\n",
    "print(df.groupby('difficulty').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## 1. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['sentence']\n",
    "# Lemmatization # we use fr_core_news_md because we are working with French text\n",
    "import spacy\n",
    "nlp = spacy.load('fr_core_news_md')\n",
    "# Assuming X is a pandas Series\n",
    "def lemmatize_text(doc):\n",
    "    return ' '.join([token.lemma_ for token in doc])\n",
    "\n",
    "# Use spaCy's pipe method for more efficient batch processing\n",
    "lemmatized_texts = [lemmatize_text(doc) for doc in nlp.pipe(X)]\n",
    "\n",
    "# Convert list back to pandas Series if necessary\n",
    "X_lemmatized = pd.Series(lemmatized_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the data into train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {'A1': 0, 'A2': 1, 'B1': 2, 'B2': 3, 'C1': 4, 'C2': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "y = df['difficulty'].values\n",
    "\n",
    "# Define the order of your labels\n",
    "labels_ordered = ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Manually fit the encoder to the ordered labels\n",
    "encoder.fit(labels_ordered)\n",
    "\n",
    "# Encode your actual labels\n",
    "y_encoded = encoder.transform(y)\n",
    "\n",
    "# Output the encoding to verify\n",
    "label_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
    "print(\"Label mapping:\", label_mapping)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lemmatized, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification, FlaubertTokenizer, FlaubertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "# 1) tokenization > used to encode the sentences\n",
    "# we could do the tokenization either with Camembert or Flaubert\n",
    "# 2) padding > used to make all the sentences of the same length\n",
    "# 3) attention masks > to give the same weight to all the words, regardless of their length\n",
    "num_classes = df['difficulty'].nunique()\n",
    "chosen_tokenizer = 'camembert'\n",
    "\n",
    "if chosen_tokenizer == 'camembert':\n",
    "    tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
    "    model = CamembertForSequenceClassification.from_pretrained('camembert-base', num_labels=num_classes)\n",
    "elif chosen_tokenizer == 'flaubert':\n",
    "    tokenizer = FlaubertTokenizer.from_pretrained('flaubert/flaubert_base_cased')\n",
    "    model = FlaubertForSequenceClassification.from_pretrained('flaubert/flaubert_base_cased', num_labels=num_classes)\n",
    "\n",
    "tokenized = X_train.apply((lambda x_: tokenizer.encode(x_, add_special_tokens=True)))\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "# now we load the data into a torch dataloader \n",
    "# respecting the input expected by the BERT model\n",
    "\n",
    "input_ids = torch.tensor(padded)\n",
    "#create the attention mask copying with sourceTensor.clone()\n",
    "attention_mask_tensor = torch.tensor(attention_mask)\n",
    "labels = torch.tensor(y_train)\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "dataset = TensorDataset(input_ids, attention_mask_tensor, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32)\n",
    "from transformers import  get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 1.6941598991552989\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "from tqdm import tqdm\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "epochs = 1\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    loss_train_total = 0\n",
    "    progress_bar = tqdm(dataloader, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch[0]))})\n",
    "    torch.save(model.state_dict(), f'BERT_ft_epoch{epoch}.model')\n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    loss_train_avg = loss_train_total/len(dataloader)\n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Levels\n",
    "We can now use our model to predict the level of a text. To do this, we need to correctly encode our text in the same way as our data was encoded during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/960 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/vaienti/miniforge3/envs/cartogenealogy/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████| 960/960 [01:28<00:00, 10.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.42      0.94      0.58       166\n",
      "          A2       0.29      0.15      0.19       158\n",
      "          B1       0.42      0.10      0.17       166\n",
      "          B2       0.44      0.12      0.19       153\n",
      "          C1       0.29      0.11      0.16       152\n",
      "          C2       0.37      0.83      0.51       165\n",
      "\n",
      "    accuracy                           0.38       960\n",
      "   macro avg       0.37      0.37      0.30       960\n",
      "weighted avg       0.37      0.38      0.30       960\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_text(text, device):\n",
    "    encoded_text = tokenizer.encode_plus(\n",
    "        text,\n",
    "        max_length=128,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    input_ids = encoded_text['input_ids'].to(device)\n",
    "    attention_mask = encoded_text['attention_mask'].to(device)\n",
    "    output = model(input_ids, attention_mask)\n",
    "    _, prediction = torch.max(output[0], dim=1)\n",
    "    return prediction[0].item()\n",
    "\n",
    "y_pred = []\n",
    "for text in tqdm(X_test):\n",
    "    y_pred.append(predict_text(text, device))\n",
    "    \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, target_names=['A1', 'A2', 'B1', 'B2', 'C1', 'C2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cartogenealogy",
   "language": "python",
   "name": "cartogenealogy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
